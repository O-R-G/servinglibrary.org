#!/bin/sh

# backup (local)
#
# dump .sql & sync media/* to ~/
# add cron job on production server
# errors to $LOG

DATE=`date +%Y-%m-%d`
HOME_LOCAL="/home/username"
WWW_LOCAL="/Library/Webserver/Documents/servinglibrary.local"
# BACKUP_LOCAL="$HOME_LOCAL/backup/sitename"
BACKUP_LOCAL="$WWW_LOCAL/sql"
SQL="$BACKUP_LOCAL/$DATE.sql"
LOG="$WWW_LOCAL/static/bash/log"
DB_USER_LOCAL="username"
DB_PASS_LOCAL="password"
DB_HOST_LOCAL="database host"
DB_NAME_LOCAL="database name"
SQL_SIZE_LIMIT=2097152 #1gb. unit: 512 bytes

echo "\n$DATE" >>$LOG
if [ ! -d "$BACKUP_LOCAL" ]; then
    mkdir $BACKUP_LOCAL 2>>$LOG;
    echo "$BACKUP_LOCAL created." 
fi

echo "\nStart mysqldump ..."
mysqldump -u $DB_USER_LOCAL -p$DB_PASS_LOCAL -h $DB_HOST_LOCAL $DB_NAME_LOCAL > $SQL 2>>$LOG
echo "\nStart rsync ..."
rsync -azP $WWW_LOCAL/media/ $BACKUP_LOCAL/media 2>>$LOG

echo "\nScanning backup folder size ..."
SQL_SIZE=`du -sc "$BACKUP_LOCAL/"*.sql | tail -n1 | cut -f1`
echo "SQL_SIZE=$SQL_SIZE"
if [ $SQL_SIZE -gt $SQL_SIZE_LIMIT ]; then
    echo "Backup folder reachs maximum size. Start rm old sql ..."
    rm "$(ls -t "$BACKUP_LOCAL/"*.sql | tail -1)"
    SQL_SIZE=`du -sc "$BACKUP_LOCAL/"*.sql | tail -n1 | cut -f1`
    while [ $SQL_SIZE -gt $SQL_SIZE_LIMIT ]
    do
        rm "$(ls -t "$BACKUP_LOCAL/"*.sql | tail -1)"
        SQL_SIZE=`du -sc "$BACKUP_LOCAL/"*.sql | tail -n1 | cut -f1`
    done
fi